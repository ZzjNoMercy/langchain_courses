{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41e6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b800a",
   "metadata": {},
   "source": [
    "上下文工程（Context Engineering）是构建基于大语言模型（LLM）应用时的一项核心设计实践，指的是有意识地设计、组织和优化输入给 LLM 的上下文内容（context），以引导模型生成更准确、可靠、安全且符合预期的输出。\n",
    "你可以把它理解为 “给 AI 写提示词的艺术与科学”，但它的范围远不止于写一条 prompt，而是涵盖整个输入信息流的结构化管理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0e4ce",
   "metadata": {},
   "source": [
    "# 上下文类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f960b2",
   "metadata": {},
   "source": [
    "| 上下文类型（Context Type） | 可以控制的内容 | 临时性 or 持久性 |\n",
    "|--------------------------|----------------|------------------|\n",
    "| 模型上下文（Model Context） | 输入到模型调用中的内容（指令、消息历史、工具列表、响应格式等） | 临时性（Transient） |\n",
    "| 工具上下文（Tool Context） | 工具可以访问和生成的内容（对状态、存储、运行时上下文的读写操作） | 持久性（Persistent） |\n",
    "| 生命周期上下文（Life-cycle Context） | 模型调用与工具执行之间发生的操作（如摘要生成、安全护栏、日志记录等） | 持久性（Persistent） |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a1161",
   "metadata": {},
   "source": [
    "- 临时上下文（Transient context）：指大语言模型（LLM）在单次调用中所看到的内容。你可以修改消息、工具或提示词，而无需改变状态中保存的数据。\n",
    "- 持久上下文（Persistent context）：指在多轮交互中被保存到状态（state）中的内容。生命周期钩子（life-cycle hooks）和工具的写入操作会永久性地修改这一上下文。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0e36de",
   "metadata": {},
   "source": [
    "> “临时” vs “持久” 的分界线不是“是否存到硬盘”，而是“是否跨越单次 LLM 调用”：\n",
    "- Transient：只活在一次模型请求里。\n",
    "- Persistent：活在整个智能体任务生命周期里（哪怕只是内存中的多轮对话）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209cbce0",
   "metadata": {},
   "source": [
    "# 数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c26768",
   "metadata": {},
   "source": [
    "在整个流程中，Agent会访问（读取/写入）不同类型的数据源：\n",
    "\n",
    "| 数据源 | 别名 | 作用范围 | 示例 |\n",
    "|--------|------|----------|------|\n",
    "| 运行时上下文（Runtime Context） | 静态配置 | 单次对话范围内 | 用户 ID、API 密钥、数据库连接、权限信息、环境设置 |\n",
    "| 状态（State） | 短期记忆 | 单次对话范围内 | 当前消息记录、上传的文件、认证状态、工具调用结果 |\n",
    "| 存储（Store） | 长期记忆 | 跨对话（持久化） | 用户偏好设置、提取的洞察信息、记忆数据、历史记录 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe83ff4",
   "metadata": {},
   "source": [
    "# 模型上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089daf4",
   "metadata": {},
   "source": [
    "## system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef7843",
   "metadata": {},
   "source": [
    "利用dynamic_prompt这个中间件，我们可以很容易根据运行时上下文动态修改系统提示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406407dd",
   "metadata": {},
   "source": [
    "### 根据state更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f566ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def state_aware_prompt(request: ModelRequest) -> str:\n",
    "    # request.messages 是 request.state[\"messages\"] 的快捷方式\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    base = \"你是一个乐于助人的助手。\"\n",
    "\n",
    "    if message_count > 10:\n",
    "        base += \"\\n这是一场很长的对话，请回答得格外简洁。\"\n",
    "\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[state_aware_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e80cc0",
   "metadata": {},
   "source": [
    "### 根据store修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b04292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str  # 用户ID\n",
    "\n",
    "@dynamic_prompt\n",
    "def store_aware_prompt(request: ModelRequest) -> str:\n",
    "    # 从运行时上下文中获取用户ID\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    # 读取存储：获取用户偏好\n",
    "    store = request.runtime.store\n",
    "    user_prefs = store.get((\"preferences\",), user_id)\n",
    "\n",
    "    base = \"你是一个乐于助人的助手。\"\n",
    "\n",
    "    if user_prefs:\n",
    "        # 如果有用户偏好，获取沟通风格（默认为 balanced）\n",
    "        style = user_prefs.value.get(\"communication_style\", \"balanced\")\n",
    "        base += f\"\\n用户偏好{style}风格的回答。\"\n",
    "\n",
    "    return base\n",
    "\n",
    "# 创建智能体\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],  # 工具列表\n",
    "    middleware=[store_aware_prompt],  # 中间件：动态提示\n",
    "    context_schema=Context,  # 上下文模式：定义需要的上下文数据结构\n",
    "    store=InMemoryStore()  # 使用内存存储\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790d3e2",
   "metadata": {},
   "source": [
    "### 根据context修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_role: str        # 用户角色\n",
    "    deployment_env: str   # 部署环境\n",
    "\n",
    "@dynamic_prompt\n",
    "def context_aware_prompt(request: ModelRequest) -> str:\n",
    "    # 从运行时上下文中读取：用户角色和环境\n",
    "    user_role = request.runtime.context.user_role\n",
    "    env = request.runtime.context.deployment_env\n",
    "\n",
    "    base = \"你是一个乐于助人的助手。\"\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        base += \"\\n你拥有管理员权限，可以执行所有操作。\"\n",
    "    elif user_role == \"viewer\":\n",
    "        base += \"\\n你仅有只读权限，请仅引导用户进行读取操作。\"\n",
    "\n",
    "    if env == \"production\":\n",
    "        base += \"\\n当前为生产环境，请格外小心任何数据修改操作。\"\n",
    "\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[context_aware_prompt],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db1782",
   "metadata": {},
   "source": [
    "## 消息列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1e3a6",
   "metadata": {},
   "source": [
    "> 注意以下案例均使用wrap_model_call 实现临时更新—— 仅修改单次模型调用时发送给模型的消息内容，不会改变状态（state）中存储的信息。如果需要永久修改状态，需使用 before_model 或 after_model 等生命周期钩子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc436a8",
   "metadata": {},
   "source": [
    "### 根据state修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7373b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_file_context(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"注入关于用户本会话上传文件的上下文信息。\"\"\"\n",
    "    # 从状态中读取：获取已上传文件的元数据\n",
    "    uploaded_files = request.state.get(\"uploaded_files\", [])  \n",
    "\n",
    "    if uploaded_files:\n",
    "        # 构建可用文件的上下文描述\n",
    "        file_descriptions = []\n",
    "        for file in uploaded_files:\n",
    "            file_descriptions.append(\n",
    "                f\"- {file['name']} ({file['type']}): {file['summary']}\"\n",
    "            )\n",
    "\n",
    "        file_context = f\"\"\"本对话中你可以访问的文件：\n",
    "{chr(10).join(file_descriptions)}\n",
    "\n",
    "回答问题时请参考这些文件。\"\"\"\n",
    "\n",
    "        # 在最近的消息前注入文件上下文\n",
    "        messages = [  \n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": file_context},\n",
    "        ]\n",
    "        request = request.override(messages=messages)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[inject_file_context]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42722cfa",
   "metadata": {},
   "source": [
    "### 根据store修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str  # 用户ID\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_writing_style(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"从存储中注入用户的邮件写作风格。\"\"\"\n",
    "    user_id = request.runtime.context.user_id  \n",
    "\n",
    "    # 从存储中读取：获取用户的写作风格示例\n",
    "    store = request.runtime.store  \n",
    "    writing_style = store.get((\"writing_style\",), user_id)  \n",
    "\n",
    "    if writing_style:\n",
    "        style = writing_style.value\n",
    "        # 根据存储的示例构建风格指南\n",
    "        style_context = f\"\"\"你的写作风格：\n",
    "- 语气 (Tone): {style.get('tone', 'professional')}\n",
    "- 常用问候语: \"{style.get('greeting', 'Hi')}\"\n",
    "- 常用结束语: \"{style.get('sign_off', 'Best')}\"\n",
    "- 你写过的邮件示例：\n",
    "{style.get('example_email', '')}\"\"\"\n",
    "\n",
    "        # 追加在消息末尾 - 模型通常更关注最后的消息\n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": style_context}\n",
    "        ]\n",
    "        request = request.override(messages=messages)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[inject_writing_style],\n",
    "    context_schema=Context,\n",
    "    store=InMemoryStore()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80076559",
   "metadata": {},
   "source": [
    "### 根据context修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_jurisdiction: str  # 用户所属司法管辖区\n",
    "    industry: str           # 所属行业\n",
    "    compliance_frameworks: list[str]  # 合规框架列表\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_compliance_rules(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"从运行时上下文中注入合规约束。\"\"\"\n",
    "    # 从运行时上下文中读取：获取合规要求\n",
    "    jurisdiction = request.runtime.context.user_jurisdiction  \n",
    "    industry = request.runtime.context.industry  \n",
    "    frameworks = request.runtime.context.compliance_frameworks  \n",
    "\n",
    "    # 构建合规规则列表\n",
    "    rules = []\n",
    "    if \"GDPR\" in frameworks:\n",
    "        rules.append(\"- 处理个人数据前必须获得明确同意\")\n",
    "        rules.append(\"- 用户拥有要求删除数据的权利\")\n",
    "    if \"HIPAA\" in frameworks:\n",
    "        rules.append(\"- 未经授权不得共享患者健康信息\")\n",
    "        rules.append(\"- 必须使用安全加密的通信方式\")\n",
    "    if industry == \"finance\":\n",
    "        rules.append(\"- 没有适当免责声明时，不得提供财务建议\")\n",
    "\n",
    "    if rules:\n",
    "        # 生成合规上下文\n",
    "        compliance_context = f\"\"\"{jurisdiction} 地区的合规要求：\n",
    "{chr(10).join(rules)}\"\"\"\n",
    "\n",
    "        # 追加在消息末尾 - 模型通常更关注最后的消息\n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": compliance_context}\n",
    "        ]\n",
    "        request = request.override(messages=messages)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[inject_compliance_rules],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603c63f",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c525360",
   "metadata": {},
   "source": [
    "这里只介绍根据state中用户的权限情况动态选择工具的案例，store和context的修改方式类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_tools(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"根据对话状态过滤可用的工具。\"\"\"\n",
    "    # 从状态中读取：检查用户是否已认证\n",
    "    state = request.state  \n",
    "    is_authenticated = state.get(\"authenticated\", False)  \n",
    "    message_count = len(state[\"messages\"])\n",
    "\n",
    "    # 仅在认证后启用敏感工具\n",
    "    if not is_authenticated:\n",
    "        # 过滤工具列表，仅保留名称以 \"public_\" 开头的公开工具\n",
    "        tools = [t for t in request.tools if t.name.startswith(\"public_\")]\n",
    "        request = request.override(tools=tools)  \n",
    "    elif message_count < 5:\n",
    "        # 在对话初期限制工具使用（例如：禁用高级搜索）\n",
    "        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n",
    "        request = request.override(tools=tools)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[public_search, private_search, advanced_search],\n",
    "    middleware=[state_based_tools]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628ea69",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d007912",
   "metadata": {},
   "source": [
    "本质上就是利用中间件来根据上下文动态选择模型，这点我们在自定义中间件章节的官方案例中已经介绍过了，这里就不再赘述了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Callable\n",
    "\n",
    "# 在中间件外部初始化模型（单例模式，避免重复初始化）\n",
    "large_model = init_chat_model(\"claude-sonnet-4-5-20250929\")\n",
    "standard_model = init_chat_model(\"gpt-4o\")\n",
    "efficient_model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_model(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"根据对话状态（消息数量）选择模型。\"\"\"\n",
    "    # request.messages 是 request.state[\"messages\"] 的快捷方式\n",
    "    message_count = len(request.messages)  \n",
    "\n",
    "    if message_count > 20:\n",
    "        # 长对话 - 使用上下文窗口更大的模型\n",
    "        model = large_model\n",
    "    elif message_count > 10:\n",
    "        # 中等长度对话\n",
    "        model = standard_model\n",
    "    else:\n",
    "        # 短对话 - 使用高性价比模型\n",
    "        model = efficient_model\n",
    "\n",
    "    # 覆写请求中的模型\n",
    "    request = request.override(model=model)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",  # 默认模型（会被中间件覆盖）\n",
    "    tools=[...],\n",
    "    middleware=[state_based_model]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86202df",
   "metadata": {},
   "source": [
    "## Response Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977b750",
   "metadata": {},
   "source": [
    "根据state、store和context动态修改Agent的响应格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Callable\n",
    "\n",
    "class SimpleResponse(BaseModel):\n",
    "    \"\"\"用于对话初期的简单响应格式。\"\"\"\n",
    "    answer: str = Field(description=\"简短的回答\")\n",
    "\n",
    "class DetailedResponse(BaseModel):\n",
    "    \"\"\"用于深入对话的详细响应格式。\"\"\"\n",
    "    answer: str = Field(description=\"详细的回答\")\n",
    "    reasoning: str = Field(description=\"推理过程\")\n",
    "    confidence: float = Field(description=\"置信度分数 0-1\")\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_output(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"根据对话状态（消息数量）选择输出格式。\"\"\"\n",
    "    # request.messages 是 request.state[\"messages\"] 的快捷方式\n",
    "    message_count = len(request.messages)  \n",
    "\n",
    "    if message_count < 3:\n",
    "        # 对话初期 - 使用简单格式\n",
    "        request = request.override(response_format=SimpleResponse)  \n",
    "    else:\n",
    "        # 对话深入后 - 使用详细格式\n",
    "        request = request.override(response_format=DetailedResponse)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[state_based_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c13ae",
   "metadata": {},
   "source": [
    "# 工具上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de058a",
   "metadata": {},
   "source": [
    "工具的特殊之处在于它们既能读取上下文，也能写入上下文。我们之前提到过，工具可以从ToolRuntime中能够读取到当前的state、store和context。本小节主要介绍工具写入上下文的相关内容。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c831214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.messages import HumanMessage, ToolMessage\n",
    "from langgraph.types import Command\n",
    "from typing import Annotated,Optional\n",
    "\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    authenticated: bool = False \n",
    "\n",
    "\n",
    "@tool\n",
    "def authenticate_user(password: str, runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"验证用户并更新状态。\"\"\"\n",
    "    # 模拟认证逻辑（实际应连接数据库/加密服务）\n",
    "    is_correct = (password.strip().lower() == \"secret123\")\n",
    "    \n",
    "    if is_correct:\n",
    "        print(\"[系统日志] 用户认证成功！\")\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [ToolMessage(content=\"用户认证成功\", tool_call_id=runtime.tool_call_id)],\"authenticated\": True\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        print(\"[系统日志] 认证失败：密码错误\")\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [ToolMessage(content=\"用户认证失败\", tool_call_id=runtime.tool_call_id)],\"authenticated\": False\n",
    "                }\n",
    "            )\n",
    "\n",
    "@tool\n",
    "def check_balance(runtime: ToolRuntime) -> ToolMessage:\n",
    "    \"\"\"检查账户余额（仅限认证用户）。\"\"\"\n",
    "    # 从运行时状态中读取认证信息\n",
    "    state = runtime.state\n",
    "    if not state.get(\"authenticated\"):\n",
    "        return {\n",
    "            \"messages\": [ToolMessage(content=\"错误：请先使用 'authenticate_user' 工具进行身份验证。\", tool_call_id=runtime.tool_call_id)]\n",
    "        }\n",
    "    else:\n",
    "        return ToolMessage(content=\"您的账户余额为：$5,000.00\", tool_call_id=runtime.tool_call_id)\n",
    "    \n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[authenticate_user, check_balance],\n",
    "    state_schema=CustomState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99fd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 我来帮您验证用户并检查余额。\n",
      "[系统日志] 用户认证成功！\n",
      "tools 用户认证成功\n",
      "model 认证成功！现在我来检查您的余额。\n",
      "tools 您的账户余额为：$5,000.00\n",
      "model 您的账户余额为：**$5,000.00**\n"
     ]
    }
   ],
   "source": [
    "for data in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"密码secret123，我的余额是多少？\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    "):\n",
    "    for event, value in data.items():\n",
    "        print(event, value[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f98ea2",
   "metadata": {},
   "source": [
    "# 生命周期上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479bb98",
   "metadata": {},
   "source": [
    "案例见SummarizationMiddleware的用法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
