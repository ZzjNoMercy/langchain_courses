{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6afc6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8560f",
   "metadata": {},
   "source": [
    "# LLMToolSelectorMiddleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11da44c",
   "metadata": {},
   "source": [
    "ä¸€ç§å¸¸è§çš„å‹ç¼©æ‰‹æ®µï¼Œåœ¨è°ƒç”¨ä¸»æ¨¡å‹ä¹‹å‰ï¼Œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½åœ°é€‰æ‹©ç›¸å…³å·¥å…·ã€‚LLM å·¥å…·é€‰æ‹©å™¨é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š\n",
    "- æ‹¥æœ‰å¤§é‡å·¥å…·ï¼ˆ10 ä¸ªä»¥ä¸Šï¼‰çš„æ™ºèƒ½ä½“ï¼Œå…¶ä¸­å¤§å¤šæ•°å·¥å…·å¯¹æ¯ä¸ªæŸ¥è¯¢å¹¶ä¸ç›¸å…³ï¼›\n",
    "- é€šè¿‡è¿‡æ»¤æ— å…³å·¥å…·æ¥å‡å°‘ token ä½¿ç”¨é‡ï¼›\n",
    "- æé«˜æ¨¡å‹çš„ä¸“æ³¨åº¦å’Œå‡†ç¡®æ€§ã€‚\n",
    "\n",
    "è¯¥ä¸­é—´ä»¶åˆ©ç”¨ç»“æ„åŒ–è¾“å‡ºï¼Œè®© LLM åˆ¤æ–­å½“å‰æŸ¥è¯¢æœ€ç›¸å…³çš„å·¥å…·æ˜¯å“ªäº›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda7a864",
   "metadata": {},
   "source": [
    "## æ„é€ å‚æ•°\n",
    "\n",
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|------|------|--------|------|\n",
    "| `model` | str \\| BaseChatModel \\| None | None | ç”¨äºé€‰æ‹©çš„æ¨¡å‹ã€‚å¦‚æœæœªæä¾›ï¼Œä½¿ç”¨ä»£ç†çš„ä¸»æ¨¡å‹ã€‚å¯ä»¥æ˜¯æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²æˆ– BaseChatModel å®ä¾‹ |\n",
    "| `system_prompt` | str | `DEFAULT_SYSTEM_PROMPT` | é€‰æ‹©æ¨¡å‹çš„æŒ‡ä»¤ |\n",
    "| `max_tools` | int \\| None | None | è¦é€‰æ‹©çš„æœ€å¤§å·¥å…·æ•°ã€‚å¦‚æœæ¨¡å‹é€‰æ‹©äº†æ›´å¤šï¼Œä»…ä½¿ç”¨å‰ `max_tools` ä¸ªã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™æ²¡æœ‰é™åˆ¶ |\n",
    "| `always_include` | list[str] \\| None | None | æ— è®ºé€‰æ‹©å¦‚ä½•éƒ½å§‹ç»ˆåŒ…å«çš„å·¥å…·åç§°ã€‚è¿™äº›ä¸è®¡å…¥ `max_tools` é™åˆ¶ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dec109",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒæ–¹æ³•\n",
    "\n",
    "| æ–¹æ³• | è¯´æ˜ |\n",
    "|------|------|\n",
    "| `_prepare_selection_request` | å‡†å¤‡å·¥å…·é€‰æ‹©çš„è¾“å…¥ |\n",
    "| `_process_selection_response` | å¤„ç†é€‰æ‹©å“åº”å¹¶è¿”å›è¿‡æ»¤åçš„ ModelRequest |\n",
    "| `wrap_model_call` /`awrap_model_call` | åœ¨é€šè¿‡å¤„ç†å™¨è°ƒç”¨æ¨¡å‹ä¹‹å‰ï¼ŒåŸºäº LLM é€‰æ‹©è¿‡æ»¤å·¥å…· |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359770d9",
   "metadata": {},
   "source": [
    "## å·¥ä½œæµç¨‹\n",
    "\n",
    "1. `_prepare_selection_request` é€»è¾‘\n",
    "\n",
    "```python\n",
    "def _prepare_selection_request(self, request: ModelRequest) -> _SelectionRequest | None:\n",
    "    # 1. æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨å·¥å…·\n",
    "    if not request.tools or len(request.tools) == 0:\n",
    "        return None\n",
    "\n",
    "    # 2. è¿‡æ»¤å‡º BaseTool å®ä¾‹ï¼ˆæ’é™¤æä¾›å•†ç‰¹å®šçš„å·¥å…·å­—å…¸ï¼‰\n",
    "    base_tools = [tool for tool in request.tools if not isinstance(tool, dict)]\n",
    "\n",
    "    # 3. éªŒè¯ always_include å·¥å…·æ˜¯å¦å­˜åœ¨\n",
    "    if self.always_include:\n",
    "        available_tool_names = {tool.name for tool in base_tools}\n",
    "        missing_tools = [\n",
    "            name for name in self.always_include if name not in available_tool_names\n",
    "        ]\n",
    "        if missing_tools:\n",
    "            raise ValueError(f\"Tools in always_include not found: {missing_tools}\")\n",
    "\n",
    "    # 4. åˆ†ç¦»å§‹ç»ˆåŒ…å«çš„å·¥å…·å’Œå¯ä¾›é€‰æ‹©çš„å·¥å…·\n",
    "    available_tools = [tool for tool in base_tools if tool.name not in self.always_include]\n",
    "\n",
    "    # 5. å¦‚æœæ²¡æœ‰å¯ä¾›é€‰æ‹©çš„å·¥å…·ï¼Œè¿”å› None\n",
    "    if not available_tools:\n",
    "        return None\n",
    "\n",
    "    # 6. å‡†å¤‡ç³»ç»Ÿæ¶ˆæ¯\n",
    "    system_message = self.system_prompt\n",
    "    if self.max_tools is not None:\n",
    "        system_message += (\n",
    "            f\"\\nIMPORTANT: List the tool names in order of relevance, \"\n",
    "            f\"with the most relevant first. \"\n",
    "            f\"If you exceed the maximum number of tools, \"\n",
    "            f\"only the first {self.max_tools} will be used.\"\n",
    "        )\n",
    "\n",
    "    # 7. è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯\n",
    "    for message in reversed(request.messages):\n",
    "        if isinstance(message, HumanMessage):\n",
    "            last_user_message = message\n",
    "            break\n",
    "\n",
    "    # 8. è¿”å›é€‰æ‹©è¯·æ±‚\n",
    "    return _SelectionRequest(\n",
    "        available_tools=available_tools,\n",
    "        system_message=system_message,\n",
    "        last_user_message=last_user_message,\n",
    "        model=self.model or request.model,\n",
    "        valid_tool_names=[tool.name for tool in available_tools],\n",
    "    )\n",
    "```\n",
    "\n",
    "2. `_process_selection_response` é€»è¾‘\n",
    "\n",
    "```python\n",
    "def _process_selection_response(\n",
    "    self,\n",
    "    response: dict,\n",
    "    available_tools: list[BaseTool],\n",
    "    valid_tool_names: list[str],\n",
    "    request: ModelRequest,\n",
    ") -> ModelRequest:\n",
    "    # 1. æå–é€‰æ‹©çš„å·¥å…·åç§°\n",
    "    selected_tool_names: list[str] = []\n",
    "    invalid_tool_selections = []\n",
    "\n",
    "    # 2. éªŒè¯é€‰æ‹©çš„å·¥å…·\n",
    "    for tool_name in response[\"tools\"]:\n",
    "        if tool_name not in valid_tool_names:\n",
    "            invalid_tool_selections.append(tool_name)\n",
    "            continue\n",
    "\n",
    "        # 3. åº”ç”¨ max_tools é™åˆ¶\n",
    "        if tool_name not in selected_tool_names and (\n",
    "            self.max_tools is None or len(selected_tool_names) < self.max_tools\n",
    "        ):\n",
    "            selected_tool_names.append(tool_name)\n",
    "\n",
    "    # 4. æ£€æŸ¥æ— æ•ˆé€‰æ‹©\n",
    "    if invalid_tool_selections:\n",
    "        raise ValueError(f\"Model selected invalid tools: {invalid_tool_selections}\")\n",
    "\n",
    "    # 5. è¿‡æ»¤å·¥å…·\n",
    "    selected_tools: list[BaseTool] = [\n",
    "        tool for tool in available_tools if tool.name in selected_tool_names\n",
    "    ]\n",
    "\n",
    "    # 6. æ·»åŠ  always_include å·¥å…·\n",
    "    always_included_tools: list[BaseTool] = [\n",
    "        tool\n",
    "        for tool in request.tools\n",
    "        if not isinstance(tool, dict) and tool.name in self.always_include\n",
    "    ]\n",
    "    selected_tools.extend(always_included_tools)\n",
    "\n",
    "    # 7. ä¿ç•™æä¾›å•†ç‰¹å®šçš„å·¥å…·å­—å…¸\n",
    "    provider_tools = [tool for tool in request.tools if isinstance(tool, dict)]\n",
    "\n",
    "    # 8. è¿”å›ä¿®æ”¹åçš„è¯·æ±‚\n",
    "    return request.override(tools=[*selected_tools, *provider_tools])\n",
    "```\n",
    "\n",
    "3. `wrap_model_call` é€»è¾‘\n",
    "\n",
    "```python\n",
    "def wrap_model_call(\n",
    "    self,\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse],\n",
    ") -> ModelCallResult:\n",
    "    # 1. å‡†å¤‡é€‰æ‹©è¯·æ±‚\n",
    "    selection_request = self._prepare_selection_request(request)\n",
    "    if selection_request is None:\n",
    "        return handler(request)\n",
    "\n",
    "    # 2. åˆ›å»ºåŠ¨æ€å“åº”æ¨¡å‹\n",
    "    type_adapter = _create_tool_selection_response(selection_request.available_tools)\n",
    "    schema = type_adapter.json_schema()\n",
    "    structured_model = selection_request.model.with_structured_output(schema)\n",
    "\n",
    "    # 3. è°ƒç”¨é€‰æ‹©æ¨¡å‹\n",
    "    response = structured_model.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": selection_request.system_message},\n",
    "            selection_request.last_user_message,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 4. éªŒè¯å“åº”\n",
    "    if not isinstance(response, dict):\n",
    "        raise AssertionError(f\"Expected dict response, got {type(response)}\")\n",
    "\n",
    "    # 5. å¤„ç†é€‰æ‹©å“åº”\n",
    "    modified_request = self._process_selection_response(\n",
    "        response,\n",
    "        selection_request.available_tools,\n",
    "        selection_request.valid_tool_names,\n",
    "        request,\n",
    "    )\n",
    "\n",
    "    # 6. è°ƒç”¨å¤„ç†å™¨\n",
    "    return handler(modified_request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40e82a",
   "metadata": {},
   "source": [
    "## ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232a2e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "æµ‹è¯• 1: æŸ¥è¯¢å¤©æ°”\n",
      "==================================================\n",
      "\n",
      "ğŸ”§ [Debug 1] ğŸš€ ====== LLMToolSelectorMiddleware å¼€å§‹ ======\n",
      "ğŸ”§ [Debug 1] 1. ä¼ å…¥çš„å·¥å…·: ['check_weather', 'query_database', 'search_knowledge_base']\n",
      "ğŸ”§ [Debug 1] 2. é€‰æ‹©æ¨¡å‹çœ‹åˆ°çš„å·¥å…·: ['check_weather', 'query_database', 'search_knowledge_base']\n",
      "ğŸ”§ [Debug 1] 3. è°ƒç”¨ super().wrap_model_call()...\n",
      "ğŸ“ [Log 1] ğŸš€ ====== LogSelectedTools å¼€å§‹ ======\n",
      "ğŸ“ [Log 1] çœ‹åˆ°çš„å·¥å…·: ['check_weather']\n",
      "ğŸ“ [Log 1] è°ƒç”¨ handler...\n",
      "ğŸ“ [Log 1] handler è¿”å›\n",
      "ğŸ“ [Log 1] ğŸš— ====== LogSelectedTools å®Œæˆ ======\n",
      "\n",
      "ğŸ”§ [Debug 1] 4. super().wrap_model_call() è¿”å›\n",
      "ğŸ”§ [Debug 1] 5. result ç±»å‹: <class 'langchain.agents.middleware.types.ModelResponse'>\n",
      "ğŸ”§ [Debug 1] 6. result å†…å®¹: ModelResponse(result=[AIMessage(content='æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 319, 'total_tokens': 371, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 63}, 'model_provider': 'deepseek', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '71f9ade6-a213-4a75-818a-98f460bd7948', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c3daa-9aac-7d93-971f-e8e4aad72dcf-0', tool_calls=[{'name': 'check_weather', 'args': {'city': 'åŒ—äº¬'}, 'id': 'call_00_62Xd0OcnUOSznbyDZCjO6Cgl', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 319, 'output_tokens': 52, 'total_tokens': 371, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}})], structured_response=None)\n",
      "ğŸ”§ [Debug 1] ğŸš— ====== LLMToolSelectorMiddleware å®Œæˆ ======\n",
      "\n",
      "\n",
      "ğŸ”§ [Debug 2] ğŸš€ ====== LLMToolSelectorMiddleware å¼€å§‹ ======\n",
      "ğŸ”§ [Debug 2] 1. ä¼ å…¥çš„å·¥å…·: ['check_weather', 'query_database', 'search_knowledge_base']\n",
      "ğŸ”§ [Debug 2] 2. é€‰æ‹©æ¨¡å‹çœ‹åˆ°çš„å·¥å…·: ['check_weather', 'query_database', 'search_knowledge_base']\n",
      "ğŸ”§ [Debug 2] 3. è°ƒç”¨ super().wrap_model_call()...\n",
      "ğŸ“ [Log 2] ğŸš€ ====== LogSelectedTools å¼€å§‹ ======\n",
      "ğŸ“ [Log 2] çœ‹åˆ°çš„å·¥å…·: ['check_weather']\n",
      "ğŸ“ [Log 2] è°ƒç”¨ handler...\n",
      "ğŸ“ [Log 2] handler è¿”å›\n",
      "ğŸ“ [Log 2] ğŸš— ====== LogSelectedTools å®Œæˆ ======\n",
      "\n",
      "ğŸ”§ [Debug 2] 4. super().wrap_model_call() è¿”å›\n",
      "ğŸ”§ [Debug 2] 5. result ç±»å‹: <class 'langchain.agents.middleware.types.ModelResponse'>\n",
      "ğŸ”§ [Debug 2] 6. result å†…å®¹: ModelResponse(result=[AIMessage(content='æ ¹æ®æŸ¥è¯¢ç»“æœï¼ŒåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œæ¸©åº¦25Â°Cã€‚å¤©æ°”ä¸é”™ï¼Œæ¸©åº¦é€‚å®œï¼Œæ˜¯ä¸ªå¥½å¤©æ°”ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 395, 'total_tokens': 420, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 384}, 'prompt_cache_hit_tokens': 384, 'prompt_cache_miss_tokens': 11}, 'model_provider': 'deepseek', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '2f1388f3-2690-4950-8e28-99d72a7a7271', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3daa-ab98-74c1-8a99-99a4b0e8db5e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 395, 'output_tokens': 25, 'total_tokens': 420, 'input_token_details': {'cache_read': 384}, 'output_token_details': {}})], structured_response=None)\n",
      "ğŸ”§ [Debug 2] ğŸš— ====== LLMToolSelectorMiddleware å®Œæˆ ======\n",
      "\n",
      "\n",
      "ğŸ’¬ å›å¤: æ ¹æ®æŸ¥è¯¢ç»“æœï¼ŒåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œæ¸©åº¦25Â°Cã€‚å¤©æ°”ä¸é”™ï¼Œæ¸©åº¦é€‚å®œï¼Œæ˜¯ä¸ªå¥½å¤©æ°”ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import LLMToolSelectorMiddleware, AgentMiddleware\n",
    "from langchain.agents.middleware.types import ModelRequest, ModelResponse, ModelCallResult\n",
    "from langchain_core.tools import tool\n",
    "from typing import Callable\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\", temperature=0.7)\n",
    "\n",
    "@tool\n",
    "def check_weather(city: str) -> str:\n",
    "    \"\"\"æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”æƒ…å†µ\n",
    "    \n",
    "    Args:\n",
    "        city: åŸå¸‚åç§°\n",
    "        \n",
    "    Returns:\n",
    "        å¤©æ°”ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"åŒ—äº¬\": \"æ™´å¤©ï¼Œæ¸©åº¦ 25Â°C\",\n",
    "        \"ä¸Šæµ·\": \"å¤šäº‘ï¼Œæ¸©åº¦ 22Â°C\",\n",
    "        \"å¹¿å·\": \"é˜´å¤©ï¼Œæ¸©åº¦ 28Â°C\",\n",
    "        \"æ·±åœ³\": \"æ™´å¤©ï¼Œæ¸©åº¦ 27Â°C\",\n",
    "    }\n",
    "    return weather_data.get(city, f\"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ° {city} çš„å¤©æ°”ä¿¡æ¯\")\n",
    "\n",
    "@tool\n",
    "def query_database(table: str, condition: str = \"\") -> str:\n",
    "    \"\"\"æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æ•°æ®\n",
    "    \n",
    "    Args:\n",
    "        table: è¡¨å\n",
    "        condition: æŸ¥è¯¢æ¡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
    "        \n",
    "    Returns:\n",
    "        æŸ¥è¯¢ç»“æœ\n",
    "    \"\"\"\n",
    "    database_data = {\n",
    "        \"users\": \"ç”¨æˆ·è¡¨åŒ…å« 1000 æ¡è®°å½•\",\n",
    "        \"orders\": \"è®¢å•è¡¨åŒ…å« 5000 æ¡è®°å½•\",\n",
    "        \"products\": \"äº§å“è¡¨åŒ…å« 200 æ¡è®°å½•\",\n",
    "    }\n",
    "    if condition:\n",
    "        return f\"ä» {table} è¡¨æŸ¥è¯¢ï¼Œæ¡ä»¶: {condition}ï¼Œç»“æœ: {database_data.get(table, 'è¡¨ä¸å­˜åœ¨')}\"\n",
    "    return f\"æŸ¥è¯¢ {table} è¡¨ï¼Œç»“æœ: {database_data.get(table, 'è¡¨ä¸å­˜åœ¨')}\"\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯\n",
    "    \n",
    "    Args:\n",
    "        query: æœç´¢å…³é”®è¯æˆ–é—®é¢˜\n",
    "        \n",
    "    Returns:\n",
    "        çŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    knowledge_base = {\n",
    "        \"å…¬å¸\": \"æˆ‘ä»¬æ˜¯ä¸€å®¶ä¸“æ³¨äº AI æŠ€æœ¯çš„å…¬å¸\",\n",
    "        \"äº§å“\": \"ä¸»è¦äº§å“åŒ…æ‹¬æ™ºèƒ½å®¢æœã€æ•°æ®åˆ†æå¹³å°ç­‰\",\n",
    "        \"æŠ€æœ¯\": \"ä½¿ç”¨æœ€æ–°çš„æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯\",\n",
    "        \"æœåŠ¡\": \"æä¾› 7x24 å°æ—¶æŠ€æœ¯æ”¯æŒæœåŠ¡\",\n",
    "    }\n",
    "    for key, value in knowledge_base.items():\n",
    "        if key in query:\n",
    "            return f\"çŸ¥è¯†åº“æœç´¢ç»“æœ: {value}\"\n",
    "    return f\"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°å…³äº '{query}' çš„ä¿¡æ¯\"\n",
    "\n",
    "\n",
    "class DebugToolSelectorMiddleware(LLMToolSelectorMiddleware):\n",
    "    \"\"\"è°ƒè¯•å·¥å…·é€‰æ‹©ä¸­é—´ä»¶\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._call_count = 0\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelCallResult:\n",
    "        self._call_count += 1\n",
    "        call_id = self._call_count\n",
    "        print(f\"\\nğŸ”§ [Debug {call_id}] ğŸš€ ====== LLMToolSelectorMiddleware å¼€å§‹ ======\")\n",
    "        print(f\"ğŸ”§ [Debug {call_id}] 1. ä¼ å…¥çš„å·¥å…·: {[tool.name for tool in request.tools]}\")\n",
    "        \n",
    "        selection_request = self._prepare_selection_request(request)\n",
    "        if selection_request is not None:\n",
    "            print(f\"ğŸ”§ [Debug {call_id}] 2. é€‰æ‹©æ¨¡å‹çœ‹åˆ°çš„å·¥å…·: {[tool.name for tool in selection_request.available_tools]}\")\n",
    "        \n",
    "        print(f\"ğŸ”§ [Debug {call_id}] 3. è°ƒç”¨ super().wrap_model_call()...\")\n",
    "        result = super().wrap_model_call(request, handler)\n",
    "        print(f\"ğŸ”§ [Debug {call_id}] 4. super().wrap_model_call() è¿”å›\")\n",
    "        \n",
    "        print(f\"ğŸ”§ [Debug {call_id}] 5. result ç±»å‹: {type(result)}\")\n",
    "        print(f\"ğŸ”§ [Debug {call_id}] 6. result å†…å®¹: {result}\")\n",
    "        if hasattr(result, 'response'):\n",
    "            print(f\"ğŸ”§ [Debug {call_id}] 7. result.response ç±»å‹: {type(result.response)}\")\n",
    "            if hasattr(result.response, 'content'):\n",
    "                print(f\"ğŸ”§ [Debug {call_id}] 8. é€‰æ‹©æ¨¡å‹çš„é€‰æ‹©: {result.response.content}\")\n",
    "        \n",
    "        print(f\"ğŸ”§ [Debug {call_id}] ğŸš— ====== LLMToolSelectorMiddleware å®Œæˆ ======\\n\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class LogSelectedTools(AgentMiddleware):\n",
    "    \"\"\"è®°å½•é€‰æ‹©çš„å·¥å…·\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._call_count = 0\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self,\n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse],\n",
    "    ) -> ModelCallResult:\n",
    "        self._call_count += 1\n",
    "        call_id = self._call_count\n",
    "        print(f\"ğŸ“ [Log {call_id}] ğŸš€ ====== LogSelectedTools å¼€å§‹ ======\")\n",
    "        print(f\"ğŸ“ [Log {call_id}] çœ‹åˆ°çš„å·¥å…·: {[tool.name for tool in request.tools]}\")\n",
    "        print(f\"ğŸ“ [Log {call_id}] è°ƒç”¨ handler...\")\n",
    "        \n",
    "        result = handler(request)\n",
    "        \n",
    "        print(f\"ğŸ“ [Log {call_id}] handler è¿”å›\")\n",
    "        print(f\"ğŸ“ [Log {call_id}] ğŸš— ====== LogSelectedTools å®Œæˆ ======\\n\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "tool_selector = DebugToolSelectorMiddleware(\n",
    "    model=model,\n",
    "    max_tools=1\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[check_weather, query_database, search_knowledge_base],\n",
    "    middleware=[tool_selector, LogSelectedTools()]\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"æµ‹è¯• 1: æŸ¥è¯¢å¤©æ°”\")\n",
    "print(\"=\" * 50)\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\")]\n",
    "})\n",
    "print(f\"\\nğŸ’¬ å›å¤: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1d44f",
   "metadata": {},
   "source": [
    "æµç¨‹æ€»ç»“ï¼šé…ç½®é¡ºåº`[tool_selector, LogSelectedTools]`æ„å‘³ç€ tool_selector åœ¨å¤–å±‚ï¼Œ LogSelectedTools åœ¨å†…å±‚ã€‚ tool_selectorå…ˆæ‰§è¡Œwrap_model_callï¼Œè¿‡æ»¤å·¥å…·åä¼ ç»™ LogSelectedTools.wrap_model_callï¼Œæ‰€ä»¥ LogSelectedToolsçœ‹åˆ°çš„æ˜¯è¿‡æ»¤åçš„1ä¸ªå·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56366f",
   "metadata": {},
   "source": [
    "# RetryMiddleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10437f5",
   "metadata": {},
   "source": [
    "ToolRetryMiddleware/ModelRetryMiddlewareåˆå¹¶åˆ°ä¸€èµ·æ¥ä»‹ç»ï¼Œä»–ä»¬éƒ½æ”¯æŒè‡ªåŠ¨å¯¹å¤±è´¥çš„è°ƒç”¨è¿›è¡Œé‡è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68abfeb",
   "metadata": {},
   "source": [
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | ModelRetryMiddleware | ToolRetryMiddleware | è¯´æ˜ |\n",
    "|------|------|--------|---------------------|---------------------|------|\n",
    "| `max_retries` | `number` | `2` | âœ… | âœ… | åˆå§‹è°ƒç”¨å¤±è´¥åçš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤å…±å°è¯•3æ¬¡ï¼ŒåŒ…æ‹¬åˆå§‹è°ƒç”¨ï¼‰ |\n",
    "| `tools` | `list[BaseTool \\| str]` | `None` | âŒ | âœ… | å¯é€‰çš„å·¥å…·åˆ—è¡¨æˆ–å·¥å…·åç§°åˆ—è¡¨ï¼Œç”¨äºæŒ‡å®šåº”ç”¨é‡è¯•é€»è¾‘çš„èŒƒå›´ã€‚è‹¥ä¸º`None`ï¼Œåˆ™å¯¹æ‰€æœ‰å·¥å…·ç”Ÿæ•ˆ |\n",
    "| `retry_on` | `tuple[type[Exception], ...] \\| callable` | `(Exception,)` | âœ… | âœ… | å¯ä¸ºä¸€ä¸ªå¼‚å¸¸ç±»å‹å…ƒç»„ï¼Œè¡¨ç¤ºåœ¨è¿™äº›å¼‚å¸¸å‘ç”Ÿæ—¶è¿›è¡Œé‡è¯•ï¼›ä¹Ÿå¯ä¸ºä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œæ¥æ”¶å¼‚å¸¸å®ä¾‹å¹¶è¿”å›`True`è¡¨ç¤ºåº”é‡è¯• |\n",
    "| `on_failure` | `string \\| callable` | `\"return_message\"` | âœ… | âœ… | å½“æ‰€æœ‰é‡è¯•å‡å¤±è´¥åçš„å¤„ç†è¡Œä¸ºã€‚é€‰é¡¹åŒ…æ‹¬ï¼š`'return_message'`ã€`'raise'`ã€è‡ªå®šä¹‰å¯è°ƒç”¨å¯¹è±¡ |\n",
    "| `backoff_factor` | `number` | `2.0` | âœ… | âœ… | æŒ‡æ•°é€€é¿çš„ä¹˜æ•°å› å­ã€‚æ¯æ¬¡é‡è¯•çš„ç­‰å¾…æ—¶é—´ä¸º `initial_delay * (backoff_factor ** retry_number)` ç§’ã€‚è®¾ä¸º`0.0`è¡¨ç¤ºä½¿ç”¨å›ºå®šå»¶è¿Ÿã€‚éšç€å¤±è´¥æ¬¡æ•°å¢åŠ ï¼Œé€æ­¥æ‹‰é•¿ç­‰å¾…æ—¶é—´ï¼Œç»™å¤–éƒ¨ç³»ç»Ÿæ›´å¤šæ¢å¤æœºä¼š |\n",
    "| `initial_delay` | `number` | `1.0` | âœ… | âœ… | é¦–æ¬¡é‡è¯•å‰çš„åˆå§‹å»¶è¿Ÿæ—¶é—´ï¼ˆå•ä½ï¼šç§’ï¼‰ |\n",
    "| `max_delay` | `number` | `60.0` | âœ… | âœ… | é‡è¯•ä¹‹é—´å»¶è¿Ÿçš„æœ€å¤§å€¼ï¼ˆå•ä½ï¼šç§’ï¼‰ï¼Œç”¨äºé™åˆ¶æŒ‡æ•°é€€é¿çš„å¢é•¿ä¸Šé™ |\n",
    "| `jitter` | `boolean` | `true` | âœ… | âœ… | æ˜¯å¦åœ¨å»¶è¿Ÿä¸­åŠ å…¥éšæœºæŠ–åŠ¨ï¼ˆÂ±25%ï¼‰ï¼Œä»¥é¿å…\"æƒŠç¾¤æ•ˆåº”\"ï¼ˆthundering herdï¼‰ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde9e77",
   "metadata": {},
   "source": [
    "**ToolRetryMiddleware æ¯” ModelRetryMiddleware å¤šä¸€ä¸ª `tools` å‚æ•°ï¼Œç”¨äºæŒ‡å®šåªé‡è¯•ç‰¹å®šå·¥å…·ã€‚**\n",
    "\n",
    "- `tools=None`ï¼šé‡è¯•æ‰€æœ‰å·¥å…·ï¼ˆé»˜è®¤ï¼‰\n",
    "- `tools=[\"tool1\", \"tool2\"]`ï¼šåªé‡è¯•æŒ‡å®šåç§°çš„å·¥å…·\n",
    "- `tools=[search_tool, db_tool]`ï¼šåªé‡è¯•æŒ‡å®šçš„å·¥å…·å®ä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3788d",
   "metadata": {},
   "source": [
    "å·¥å…·é‡è¯•ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b442f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ToolRetryMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, database_tool, api_tool],\n",
    "    middleware=[\n",
    "        ToolRetryMiddleware(\n",
    "            max_retries=3,\n",
    "            backoff_factor=2.0,\n",
    "            initial_delay=1.0,\n",
    "            max_delay=60.0,\n",
    "            jitter=True,\n",
    "            tools=[\"api_tool\"],\n",
    "            retry_on=(ConnectionError, TimeoutError),\n",
    "            on_failure=\"continue\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62b5c8",
   "metadata": {},
   "source": [
    "æ¨¡å‹é‡è¯•ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a84f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ModelRetryMiddleware\n",
    "\n",
    "\n",
    "# åŸºç¡€ç”¨æ³•ï¼šä½¿ç”¨é»˜è®¤è®¾ç½®ï¼ˆ2æ¬¡é‡è¯•ï¼ŒæŒ‡æ•°é€€é¿ï¼‰\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool],\n",
    "    middleware=[ModelRetryMiddleware()],\n",
    ")\n",
    "\n",
    "# è‡ªå®šä¹‰å¼‚å¸¸è¿‡æ»¤\n",
    "class TimeoutError(Exception):\n",
    "    \"\"\"è‡ªå®šä¹‰è¶…æ—¶å¼‚å¸¸ã€‚\"\"\"\n",
    "    pass\n",
    "\n",
    "class ConnectionError(Exception):\n",
    "    \"\"\"è‡ªå®šä¹‰è¿æ¥å¼‚å¸¸ã€‚\"\"\"\n",
    "    pass\n",
    "\n",
    "# ä»…é’ˆå¯¹ç‰¹å®šå¼‚å¸¸è¿›è¡Œé‡è¯•\n",
    "retry = ModelRetryMiddleware(\n",
    "    max_retries=4, # æœ€å¤šé‡è¯•4æ¬¡\n",
    "    retry_on=(TimeoutError, ConnectionError), # ä»…åœ¨å‘ç”Ÿè¿™ä¸¤ç§å¼‚å¸¸æ—¶é‡è¯•\n",
    "    backoff_factor=1.5, # é€€é¿å› å­\n",
    ")\n",
    "\n",
    "\n",
    "# è‡ªå®šä¹‰é‡è¯•åˆ¤æ–­é€»è¾‘\n",
    "def should_retry(error: Exception) -> bool:\n",
    "    # ä»…åœ¨å‘ç”Ÿé™æµé”™è¯¯æ—¶é‡è¯•\n",
    "    if isinstance(error, TimeoutError):\n",
    "        return True\n",
    "    # æˆ–è€…æ£€æŸ¥ç‰¹å®šçš„ HTTP çŠ¶æ€ç \n",
    "    if hasattr(error, \"status_code\"):\n",
    "        return error.status_code in (429, 503) # 429: é™æµ, 503: æœåŠ¡ä¸å¯ç”¨\n",
    "    return False\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰è¿‡æ»¤å‡½æ•°\n",
    "retry_with_filter = ModelRetryMiddleware(\n",
    "    max_retries=3,\n",
    "    retry_on=should_retry,\n",
    ")\n",
    "\n",
    "# å¤±è´¥åè¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸\n",
    "retry_continue = ModelRetryMiddleware(\n",
    "    max_retries=4,\n",
    "    on_failure=\"continue\",  # å‘ç”Ÿå¤±è´¥æ—¶è¿”å› AIMessage é”™è¯¯ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸\n",
    ")\n",
    "\n",
    "# è‡ªå®šä¹‰é”™è¯¯ä¿¡æ¯æ ¼å¼\n",
    "def format_error(error: Exception) -> str:\n",
    "    return f\"æ¨¡å‹è°ƒç”¨å¤±è´¥: {error}ã€‚è¯·ç¨åå†è¯•ã€‚\"\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼åŒ–å‡½æ•°\n",
    "retry_with_formatter = ModelRetryMiddleware(\n",
    "    max_retries=4,\n",
    "    on_failure=format_error,\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨å›ºå®šé€€é¿æ—¶é—´ï¼ˆæ— æŒ‡æ•°å¢é•¿ï¼‰\n",
    "constant_backoff = ModelRetryMiddleware(\n",
    "    max_retries=5,\n",
    "    backoff_factor=0.0,  # ç¦ç”¨æŒ‡æ•°å¢é•¿\n",
    "    initial_delay=2.0,  # æ¯æ¬¡å›ºå®šç­‰å¾… 2 ç§’\n",
    ")\n",
    "\n",
    "# ä¸¥æ ¼æ¨¡å¼ï¼šå¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºå¼‚å¸¸\n",
    "strict_retry = ModelRetryMiddleware(\n",
    "    max_retries=2,\n",
    "    on_failure=\"error\",  # å‘ç”Ÿå¤±è´¥æ—¶ç›´æ¥é‡æ–°æŠ›å‡ºå¼‚å¸¸\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0072c95",
   "metadata": {},
   "source": [
    "# LLMToolEmulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0f5da",
   "metadata": {},
   "source": [
    "ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œï¼Œç”¨äºæµ‹è¯•ç›®çš„ï¼Œå°†å®é™…çš„å·¥å…·è°ƒç”¨æ›¿æ¢ä¸º AI ç”Ÿæˆçš„å“åº”ã€‚LLM å·¥å…·æ¨¡æ‹Ÿå™¨é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š\n",
    "- åœ¨ä¸æ‰§è¡ŒçœŸå®å·¥å…·çš„æƒ…å†µä¸‹æµ‹è¯•æ™ºèƒ½ä½“çš„è¡Œä¸ºï¼›\n",
    "- åœ¨å¤–éƒ¨å·¥å…·ä¸å¯ç”¨æˆ–è°ƒç”¨æˆæœ¬è¾ƒé«˜æ—¶å¼€å‘æ™ºèƒ½ä½“ï¼›\n",
    "- åœ¨å®ç°çœŸå®å·¥å…·ä¹‹å‰ï¼Œå¯¹æ™ºèƒ½ä½“å·¥ä½œæµè¿›è¡ŒåŸå‹è®¾è®¡å’ŒéªŒè¯ã€‚\n",
    "\n",
    "åº•å±‚æ˜¯ä¾é wrap_tool_callæ¥å®ç°çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bc92e",
   "metadata": {},
   "source": [
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|------|------|--------|------|\n",
    "| `tools` | `list[str \\| BaseTool] \\| None` | `None` | è¦æ¨¡æ‹Ÿçš„å·¥å…·åˆ—è¡¨ã€‚`None` è¡¨ç¤ºæ¨¡æ‹Ÿæ‰€æœ‰å·¥å…·ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºä¸æ¨¡æ‹Ÿä»»ä½•å·¥å…· |\n",
    "| `model` | `str \\| BaseChatModel \\| None` | `'anthropic:claude-sonnet-4-5-20250929'` | ç”¨äºæ¨¡æ‹Ÿçš„æ¨¡å‹ã€‚å¯ä»¥æ˜¯æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²æˆ– `BaseChatModel` å®ä¾‹ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7abfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import LLMToolEmulator\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# å®šä¹‰è·å–å¤©æ°”çš„å·¥å…·\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"è·å–æŒ‡å®šåœ°ç‚¹çš„å½“å‰å¤©æ°”ã€‚\"\"\"\n",
    "    return f\"Weather in {location}\"\n",
    "\n",
    "# å®šä¹‰å‘é€é‚®ä»¶çš„å·¥å…·\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"å‘é€é‚®ä»¶ã€‚\"\"\"\n",
    "    return \"Email sent\"\n",
    "\n",
    "\n",
    "# æ–¹å¼ä¸€ï¼šæ¨¡æ‹Ÿæ‰€æœ‰å·¥å…·ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰\n",
    "# å¦‚æœ LLM æ— æ³•è°ƒç”¨å·¥å…·ï¼Œä¸­é—´ä»¶ä¼šå°è¯•ç”¨è‡ªç„¶è¯­è¨€æ¨¡æ‹Ÿå·¥å…·çš„æ‰§è¡Œç»“æœ\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_weather, send_email],\n",
    "    middleware=[LLMToolEmulator()],\n",
    ")\n",
    "\n",
    "# æ–¹å¼äºŒï¼šä»…æ¨¡æ‹ŸæŒ‡å®šçš„å·¥å…·\n",
    "# åªå¯¹ get_weather å·¥å…·è¿›è¡Œæ¨¡æ‹Ÿï¼Œå…¶ä»–å·¥å…·ä¿æŒåŸæ ·\n",
    "agent2 = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_weather, send_email],\n",
    "    middleware=[LLMToolEmulator(tools=[\"get_weather\"])],\n",
    ")\n",
    "\n",
    "# æ–¹å¼å››ï¼šä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹è¿›è¡Œæ¨¡æ‹Ÿ\n",
    "# æŒ‡å®šä½¿ç”¨ claude æ¨¡å‹æ¥æ¨¡æ‹Ÿå·¥å…·çš„è¡Œä¸º\n",
    "agent4 = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_weather, send_email],\n",
    "    middleware=[LLMToolEmulator(model=\"claude-sonnet-4-5-20250929\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa0ef8",
   "metadata": {},
   "source": [
    "# ContextEditingMiddleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715237a8",
   "metadata": {},
   "source": [
    "å½“è¾¾åˆ°tokené™åˆ¶æ—¶ï¼Œé€šè¿‡æ¸…é™¤è¾ƒæ—©çš„å·¥å…·è°ƒç”¨è¾“å‡ºæ¥ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶ä¿ç•™æœ€è¿‘çš„ç»“æœã€‚è¿™æœ‰åŠ©äºåœ¨åŒ…å«å¤§é‡å·¥å…·è°ƒç”¨çš„é•¿å¯¹è¯ä¸­ï¼Œä½¿ä¸Šä¸‹æ–‡çª—å£ä¿æŒåœ¨å¯æ§èŒƒå›´å†…ã€‚\n",
    "\n",
    "è¯¥ä¸­é—´ä»¶é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š\n",
    "- åŒ…å«å¤§é‡å·¥å…·è°ƒç”¨çš„é•¿å¯¹è¯ï¼Œå…¶ä¸Šä¸‹æ–‡è¶…å‡ºä»¤ç‰Œé™åˆ¶\n",
    "- é€šè¿‡ç§»é™¤ä¸å†ç›¸å…³çš„æ—§å·¥å…·è¾“å‡ºï¼Œé™ä½ä»¤ç‰Œä½¿ç”¨æˆæœ¬\n",
    "- ä»…åœ¨ä¸Šä¸‹æ–‡ä¸­ä¿ç•™æœ€è¿‘çš„ N ä¸ªå·¥å…·è°ƒç”¨ç»“æœ\n",
    "å…¶å·¥ä½œåŸç†å¦‚ä¸‹ï¼š\n",
    "- ç›‘æ§å¯¹è¯ä¸­çš„ä»¤ç‰Œæ•°é‡\n",
    "- å½“è¾¾åˆ°è®¾å®šé˜ˆå€¼æ—¶ï¼Œæ¸…é™¤è¾ƒæ—§çš„å·¥å…·è¾“å‡º\n",
    "- ä¿ç•™æœ€è¿‘çš„ N ä¸ªå·¥å…·è°ƒç”¨ç»“æœ\n",
    "- å¯é€‰æ‹©æ€§åœ°ä¿ç•™å·¥å…·è°ƒç”¨çš„å‚æ•°ä»¥ç»´æŒä¸Šä¸‹æ–‡ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f6451",
   "metadata": {},
   "source": [
    "ContextEditingMiddleware å‚æ•°\n",
    "\n",
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|------|------|--------|------|\n",
    "| `edits` | `Iterable[ContextEdit] \\| None` | `ClearToolUsesEdit()` | ç¼–è¾‘ç­–ç•¥åºåˆ—ï¼Œç”¨äºç®¡ç†ä¸Šä¸‹æ–‡å¤§å° |\n",
    "| `token_count_method` | `Literal[\"approximate\", \"model\"]` | `\"approximate\"` | Token è®¡æ•°æ–¹æ³•ï¼š`\"approximate\"`ï¼ˆå¿«é€Ÿï¼Œä¸å¤ªå‡†ç¡®ï¼‰æˆ– `\"model\"`ï¼ˆä½¿ç”¨æ¨¡å‹è®¡æ•°ï¼Œæ›´å‡†ç¡®ä½†è¾ƒæ…¢ï¼‰ |\n",
    "\n",
    "ClearToolUsesEdit å‚æ•°\n",
    "\n",
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|------|------|--------|------|\n",
    "| `trigger` | `int` | `100_000` | è§¦å‘ç¼–è¾‘çš„ token é˜ˆå€¼ |\n",
    "| `clear_at_least` | `int` | `0` | ç¼–è¾‘è¿è¡Œæ—¶è‡³å°‘å›æ”¶çš„ token æ•°é‡ |\n",
    "| `keep` | `int` | `3` | å¿…é¡»ä¿ç•™çš„æœ€æ–°å·¥å…·ç»“æœæ•°é‡ |\n",
    "| `clear_tool_inputs` | `bool` | `False` | æ˜¯å¦æ¸…é™¤ AI æ¶ˆæ¯ä¸Šçš„å·¥å…·è°ƒç”¨å‚æ•° |\n",
    "| `exclude_tools` | `Sequence[str]` | `()` | ä¸æ¸…é™¤çš„å·¥å…·åç§°åˆ—è¡¨ |\n",
    "| `placeholder` | `str` | `\"[cleared]\"` | ä¸ºæ¸…é™¤çš„å·¥å…·è¾“å‡ºæ’å…¥çš„å ä½ç¬¦æ–‡æœ¬ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, your_calculator_tool, database_tool],\n",
    "    middleware=[\n",
    "        ContextEditingMiddleware(\n",
    "            edits=[\n",
    "                ClearToolUsesEdit(\n",
    "                    trigger=2000,\n",
    "                    keep=3,\n",
    "                    clear_tool_inputs=False,\n",
    "                    exclude_tools=[],\n",
    "                    placeholder=\"[cleared]\",\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6dc87",
   "metadata": {},
   "source": [
    "# ShellToolMiddleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae8f40",
   "metadata": {},
   "source": [
    "ä¸ºAgentæä¾›ä¸€ä¸ªæŒä¹…çš„shellå·¥å…·ï¼Œå…è®¸Agentæ‰§è¡Œç³»ç»Ÿå‘½ä»¤ã€‚\n",
    "\n",
    "| åŠŸèƒ½ | è¯´æ˜ |\n",
    "|------|------|\n",
    "| **æŒä¹…ä¼šè¯** | æä¾›ä¸€ä¸ªé•¿æœŸå­˜åœ¨çš„ shell ä¼šè¯ï¼Œå‘½ä»¤æ‰§è¡ŒçŠ¶æ€ä¼šè¢«ä¿ç•™ |\n",
    "| **æ‰§è¡Œç­–ç•¥** | æ”¯æŒå¤šç§æ‰§è¡Œç­–ç•¥ï¼ˆä¸»æœºã€Codex æ²™ç®±ã€Dockerï¼‰ |\n",
    "| **å®‰å…¨æ§åˆ¶** | æ”¯æŒè¶…æ—¶ã€è¾“å‡ºé™åˆ¶ã€ç¯å¢ƒå˜é‡é…ç½® |\n",
    "| **PII è¿‡æ»¤** | å¯é…ç½® PIIï¼ˆä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰æ£€æµ‹å’Œè„±æ•è§„åˆ™ |\n",
    "| **ä¼šè¯ç®¡ç†** | æ”¯æŒå¯åŠ¨å‘½ä»¤ã€å…³é—­å‘½ä»¤ã€é‡å¯åŠŸèƒ½ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1980f6",
   "metadata": {},
   "source": [
    "\n",
    "## å‚æ•°\n",
    "\n",
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|------|------|--------|------|\n",
    "| `workspace_root` | `str \\| Path \\| None` | `None` | Shell ä¼šè¯çš„åŸºç¡€ç›®å½•ï¼Œçœç•¥åˆ™åˆ›å»ºä¸´æ—¶ç›®å½• |\n",
    "| `startup_commands` | `tuple[str, ...] \\| list[str] \\| str \\| None` | `None` | ä¼šè¯å¯åŠ¨åæ‰§è¡Œçš„å‘½ä»¤åºåˆ— |\n",
    "| `shutdown_commands` | `tuple[str, ...] \\| list[str] \\| str \\| None` | `None` | ä¼šè¯å…³é—­å‰æ‰§è¡Œçš„å‘½ä»¤ |\n",
    "| `execution_policy` | `BaseExecutionPolicy \\| None` | `HostExecutionPolicy()` | æ‰§è¡Œç­–ç•¥ï¼Œæ§åˆ¶è¶…æ—¶ã€è¾“å‡ºé™åˆ¶å’Œèµ„æºé…ç½® |\n",
    "| `redaction_rules` | `tuple[RedactionRule, ...] \\| list[RedactionRule] \\| None` | `None` | è„±æ•è§„åˆ™ï¼Œç”¨äºæ¸…ç†å‘½ä»¤è¾“å‡ºä¸­çš„æ•æ„Ÿä¿¡æ¯ |\n",
    "| `tool_description` | `str \\| None` | é»˜è®¤æè¿° | æ³¨å†Œçš„ shell å·¥å…·çš„æè¿°è¦†ç›– |\n",
    "| `tool_name` | `str` | `\"shell\"` | æ³¨å†Œçš„ shell å·¥å…·åç§° |\n",
    "| `shell_command` | `Sequence[str] \\| str \\| None` | `None` | ç”¨äºå¯åŠ¨æŒä¹…ä¼šè¯çš„ shell å¯æ‰§è¡Œæ–‡ä»¶æˆ–å‚æ•°åºåˆ— |\n",
    "| `env` | `Mapping[str, Any] \\| None` | `None` | æä¾›ç»™ shell ä¼šè¯çš„ç¯å¢ƒå˜é‡ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c4df20",
   "metadata": {},
   "source": [
    "## æ‰§è¡Œç­–ç•¥\n",
    "\n",
    "| ç­–ç•¥ | è¯´æ˜ |\n",
    "|------|------|\n",
    "| `HostExecutionPolicy` | å®Œæ•´ä¸»æœºè®¿é—®ï¼Œé€‚åˆå—ä¿¡ä»»çš„ç¯å¢ƒï¼ˆAgent å·²åœ¨å®¹å™¨æˆ– VM ä¸­è¿è¡Œï¼‰ |\n",
    "| `CodexSandboxExecutionPolicy` | å¤ç”¨ Codex CLI æ²™ç®±ï¼Œæä¾›é¢å¤–çš„ç³»ç»Ÿè°ƒç”¨/æ–‡ä»¶ç³»ç»Ÿé™åˆ¶ |\n",
    "| `DockerExecutionPolicy` | ä¸ºæ¯æ¬¡ Agent è¿è¡Œå¯åŠ¨ç‹¬ç«‹çš„ Docker å®¹å™¨ï¼Œæä¾›æ›´å¼ºçš„éš”ç¦» |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30b9e6",
   "metadata": {},
   "source": [
    "## å·¥ä½œæµç¨‹\n",
    "\n",
    "1. Agent è°ƒç”¨ shell å·¥å…·ï¼ˆä¾‹å¦‚ï¼š`shell(command=\"ls -la\")`ï¼‰\n",
    "\n",
    "2. æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯ä¼šè¯\n",
    "   - å¦‚æœ `restart=True`ï¼šé‡å¯ä¼šè¯å¹¶æ‰§è¡Œå¯åŠ¨å‘½ä»¤\n",
    "\n",
    "3. æ‰§è¡Œå‘½ä»¤\n",
    "   - `result = session.execute(command, timeout)`\n",
    "\n",
    "4. å¤„ç†è¶…æ—¶\n",
    "   - å¦‚æœè¶…æ—¶ï¼šè¿”å›è¶…æ—¶é”™è¯¯æ¶ˆæ¯\n",
    "\n",
    "5. åº”ç”¨è„±æ•è§„åˆ™\n",
    "   - æ¸…ç†è¾“å‡ºä¸­çš„æ•æ„Ÿä¿¡æ¯\n",
    "   - å¦‚æœæ£€æµ‹åˆ° PIIï¼šè¿”å›é˜»å¡é”™è¯¯æ¶ˆæ¯\n",
    "\n",
    "6. å¤„ç†è¾“å‡ºæˆªæ–­\n",
    "   - å¦‚æœè¶…è¿‡è¡Œæ•°æˆ–å­—èŠ‚æ•°é™åˆ¶ï¼šæ·»åŠ æˆªæ–­æç¤º\n",
    "\n",
    "7. å¤„ç†é€€å‡ºç \n",
    "   - å¦‚æœé€€å‡ºç é 0ï¼šæ·»åŠ é€€å‡ºç ä¿¡æ¯\n",
    "\n",
    "8. è¿”å›æ ¼å¼åŒ–çš„å·¥å…·æ¶ˆæ¯\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import (\n",
    "    ShellToolMiddleware,          # Shell å·¥å…·ä¸­é—´ä»¶\n",
    "    HostExecutionPolicy,          # ä¸»æœºæ‰§è¡Œç­–ç•¥\n",
    "    DockerExecutionPolicy,        # Docker æ‰§è¡Œç­–ç•¥\n",
    "    RedactionRule,                \n",
    ")\n",
    "\n",
    "\n",
    "# åŸºç¡€ç”¨æ³•ï¼šåœ¨ä¸»æœºä¸Šæ‰§è¡Œå‘½ä»¤\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool],\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"/workspace\",       # å·¥ä½œç©ºé—´æ ¹ç›®å½•\n",
    "            execution_policy=HostExecutionPolicy(), # æ‰§è¡Œç­–ç•¥ï¼šç›´æ¥åœ¨å®¿ä¸»æœºè¿è¡Œ\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Docker éš”ç¦»æ¨¡å¼ï¼šåŒ…å«å®¹å™¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–å‘½ä»¤\n",
    "agent_docker = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"/workspace\",\n",
    "            startup_commands=[\n",
    "                \"pip install requests\",         # å®¹å™¨å¯åŠ¨æ—¶å®‰è£…ä¾èµ–\n",
    "                \"export PYTHONPATH=/workspace\"  # è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "            ],\n",
    "            execution_policy=DockerExecutionPolicy(\n",
    "                image=\"python:3.11-slim\",       # ä½¿ç”¨çš„åŸºç¡€é•œåƒ\n",
    "                command_timeout=60.0,           # å‘½ä»¤è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# å¸¦è¾“å‡ºè„±æ•ï¼ˆçº¢actionï¼‰åŠŸèƒ½\n",
    "agent_redacted = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        ShellToolMiddleware(\n",
    "            workspace_root=\"/workspace\",\n",
    "            redaction_rules=[\n",
    "                # å®šä¹‰è„±æ•è§„åˆ™ï¼šç±»å‹ä¸º api_keyï¼ŒåŒ¹é…æ­£åˆ™è¡¨è¾¾å¼\n",
    "                RedactionRule(pii_type=\"api_key\", detector=r\"sk-[a-zA-Z0-9]{32}\"),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79b78f",
   "metadata": {},
   "source": [
    "# FilesystemFileSearchMiddleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c7e7f",
   "metadata": {},
   "source": [
    "æä¾›åŸºäºæ–‡ä»¶ç³»ç»Ÿçš„ Glob å’Œ Grep æœç´¢å·¥å…·ã€‚æ–‡ä»¶æœç´¢ä¸­é—´ä»¶é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š\n",
    "- ä»£ç æ¢ç´¢ä¸åˆ†æ\n",
    "- æŒ‰æ–‡ä»¶åæ¨¡å¼æŸ¥æ‰¾æ–‡ä»¶\n",
    "- ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æœç´¢ä»£ç å†…å®¹\n",
    "- éœ€è¦å‘ç°æ–‡ä»¶çš„å¤§å‹ä»£ç åº“\n",
    "\n",
    "è¯¥ä¸­é—´ä»¶ä¸ºæ™ºèƒ½ä½“ï¼ˆagentsï¼‰æ·»åŠ äº†ä¸¤ä¸ªæœç´¢å·¥å…·ï¼š\n",
    "- Glob å·¥å…· â€” å¿«é€Ÿæ–‡ä»¶æ¨¡å¼åŒ¹é…ï¼š\n",
    "  - æ”¯æŒå¦‚ **/*.pyã€src/**/*.ts ç­‰æ¨¡å¼\n",
    "  - è¿”å›æŒ‰ä¿®æ”¹æ—¶é—´æ’åºçš„åŒ¹é…æ–‡ä»¶è·¯å¾„\n",
    "- Grep å·¥å…· â€” åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„å†…å®¹æœç´¢ï¼š\n",
    "  - æ”¯æŒå®Œæ•´çš„æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•\n",
    "  - å¯é€šè¿‡ include å‚æ•°æŒ‰æ–‡ä»¶æ¨¡å¼è¿›è¡Œç­›é€‰\n",
    "  - æä¾›ä¸‰ç§è¾“å‡ºæ¨¡å¼ï¼šfiles_with_matchesï¼ˆå«åŒ¹é…é¡¹çš„æ–‡ä»¶ï¼‰ã€contentï¼ˆåŒ¹é…å†…å®¹ï¼‰ã€countï¼ˆåŒ¹é…æ•°é‡ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9682b35",
   "metadata": {},
   "source": [
    "##  å‚æ•°\n",
    "\n",
    "| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |\n",
    "|------|------|--------|------|\n",
    "| `root_path` | `str` | å¿…å¡« | æœç´¢çš„æ ¹ç›®å½• |\n",
    "| `use_ripgrep` | `bool` | `True` | æ˜¯å¦ä½¿ç”¨ `ripgrep` è¿›è¡Œæœç´¢ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ° Python |\n",
    "| `max_file_size_mb` | `int` | `10` | æœç´¢çš„æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ |\n",
    "\n",
    "## æä¾›çš„å·¥å…·\n",
    "\n",
    "| å·¥å…· | åŠŸèƒ½ |\n",
    "|------|------|\n",
    "| `glob` | å¿«é€Ÿæ–‡ä»¶æ¨¡å¼åŒ¹é…ï¼Œæ”¯æŒ glob æ¨¡å¼å¦‚ `**/*.js` æˆ– `src/**/*.ts` |\n",
    "| `grep` | å¿«é€Ÿå†…å®¹æœç´¢ï¼Œä½¿ç”¨ ripgrep æˆ– Python å›é€€ï¼Œæ”¯æŒæ­£åˆ™è¡¨è¾¾å¼ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c5cee",
   "metadata": {},
   "source": [
    "> ripgrepï¼ˆç®€ç§° rg ï¼‰æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºå¿«é€Ÿæœç´¢æ–‡ä»¶å†…å®¹ï¼Œéœ€è¦è¿›è¡Œå®‰è£…ï¼Œå¦‚æœæœªå®‰è£…ï¼Œä¼šå›é€€åˆ°pythonæ¥è¿›è¡Œå®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import FilesystemFileSearchMiddleware\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        FilesystemFileSearchMiddleware(\n",
    "            root_path=\"/workspace\",      # æœç´¢çš„æ ¹ç›®å½•\n",
    "            use_ripgrep=True,            # æ˜¯å¦ä½¿ç”¨ ripgrep å·¥å…·è¿›è¡Œæœç´¢ï¼ˆæ›´å¿«ï¼‰\n",
    "            max_file_size_mb=10,         # å•ä¸ªæ–‡ä»¶æœ€å¤§å¤§å°é™åˆ¶ï¼ˆMBï¼‰\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ç°åœ¨ Agent å¯ä»¥ä½¿ç”¨ glob_search å’Œ grep_search å·¥å…·äº†\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"æŸ¥æ‰¾æ‰€æœ‰åŒ…å« 'async def' çš„ Python æ–‡ä»¶\")]\n",
    "})\n",
    "\n",
    "# Agent çš„æ‰§è¡Œé€»è¾‘é€šå¸¸æ˜¯ï¼š\n",
    "# 1. å…ˆç”¨ glob_search(pattern=\"**/*.py\") æ‰¾åˆ°æ‰€æœ‰ Python æ–‡ä»¶\n",
    "# 2. å†ç”¨ grep_search(pattern=\"async def\", include=\"*.py\") åœ¨è¿™äº›æ–‡ä»¶ä¸­æœç´¢å¼‚æ­¥å‡½æ•°å®šä¹‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
